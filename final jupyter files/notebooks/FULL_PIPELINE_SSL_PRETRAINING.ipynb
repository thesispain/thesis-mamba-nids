{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eafb35c8",
   "metadata": {},
   "source": [
    "# âš¡ FULL SSL PRETRAINING PIPELINE (Smart Weight Detection)\n",
    "\n",
    "## Why This Takes Only Seconds, Not 30 Minutes:\n",
    "- **Cell 4**: Checks if weights already exist\n",
    "- **If Found** âœ…: Loads instantly (~1 second)\n",
    "- **If Missing** âŒ: Trains fresh (~30 minutes)\n",
    "- **No More Redundant Training!**\n",
    "\n",
    "---\n",
    "**This notebook solves the problem:**\n",
    "```\n",
    "Q: Why would it take 30 mins if we already have trained weights?\n",
    "A: This notebook detects weights and loads them instantly!\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dec8a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "======================================================================\n",
    "STAGE 0: IMPORTS & SETUP\n",
    "======================================================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "# Mamba imports\n",
    "from mamba_ssm import Mamba\n",
    "\n",
    "print(\"âœ… Mamba imported\")\n",
    "\n",
    "# Device setup\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"âœ… Device: {DEVICE}\")\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(f\"âš ï¸ Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76804f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "======================================================================\n",
    "STAGE 1: PATHS & DATA\n",
    "======================================================================\n",
    "\n",
    "# Absolute paths (no more ../../../)\n",
    "WORKSPACE_ROOT = Path('/home/T2510596/Downloads/totally fresh')\n",
    "DATA_DIR = WORKSPACE_ROOT / 'thesis_final' / 'data'\n",
    "WEIGHTS_DIR = WORKSPACE_ROOT / 'thesis_final' / 'weights' / 'ssl'\n",
    "WEIGHTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "pretrain_path = DATA_DIR / 'pretrain_data.pt'\n",
    "finetune_path = DATA_DIR / 'finetune_data.pt'\n",
    "final_weight_path = WEIGHTS_DIR / 'bimamba_masking_ssl_final.pth'\n",
    "\n",
    "print(f\"ğŸ“‚ Loading data...\")\n",
    "pretrain_data = torch.load(pretrain_path)\n",
    "finetune_data = torch.load(finetune_path)\n",
    "\n",
    "print(f\"âœ… Pretrain: {len(pretrain_data)} flows\")\n",
    "print(f\"âœ… Finetune: {len(finetune_data)} flows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321e27ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "======================================================================\n",
    "STAGE 2: MODEL DEFINITION\n",
    "======================================================================\n",
    "\n",
    "class PacketEmbedder(nn.Module):\n",
    "    def __init__(self, d_embed=256):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Linear(5, d_embed)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.embed(x)\n",
    "\n",
    "class BiMambaEncoder(nn.Module):\n",
    "    def __init__(self, d_model=256, n_layers=4, d_state=32):\n",
    "        super().__init__()\n",
    "        self.embedder = PacketEmbedder(d_model)\n",
    "        self.mamba_fwd = nn.Sequential(*[Mamba(d_model, d_state) for _ in range(n_layers)])\n",
    "        self.mamba_bwd = nn.Sequential(*[Mamba(d_model, d_state) for _ in range(n_layers)])\n",
    "        self.projection = nn.Linear(d_model * 2, 128)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        emb = self.embedder(x)\n",
    "        fwd = self.mamba_fwd(emb)\n",
    "        bwd = self.mamba_bwd(torch.flip(emb, [0]))\n",
    "        bwd = torch.flip(bwd, [0])\n",
    "        combined = torch.cat([fwd, bwd], dim=-1)\n",
    "        return self.projection(combined[-1])\n",
    "\n",
    "print(\"âœ… Models defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cf7e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âš¡ SMART WEIGHT DETECTION âš¡\".center(70))\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nğŸ” Checking: {final_weight_path}\\n\")\n",
    "\n",
    "if os.path.exists(final_weight_path):\n",
    "    size_mb = os.path.getsize(final_weight_path) / 1e6\n",
    "    print(f\"âœ… WEIGHTS FOUND ({size_mb:.0f} MB)!\")\n",
    "    print(f\"\\nğŸš€ LOADING WEIGHTS (skipping 30-minute training!)\\n\")\n",
    "    print(f\"â±ï¸ Time saved: ~30 minutes â­ï¸\\n\")\n",
    "    \n",
    "    encoder = BiMambaEncoder(d_model=256, n_layers=4).to(DEVICE)\n",
    "    encoder.load_state_dict(torch.load(final_weight_path, map_location=DEVICE, weights_only=False))\n",
    "    encoder.eval()\n",
    "    \n",
    "    total_params = sum(p.numel() for p in encoder.parameters())\n",
    "    print(f\"âœ… Model loaded: {total_params:,} parameters\")\n",
    "    SKIP_TRAINING = True\n",
    "else:\n",
    "    print(f\"âŒ Weights not found - training needed\")\n",
    "    SKIP_TRAINING = False\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7563ac45",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STAGE 3: ANOMALY DETECTION EVAL\".center(70))\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Extract benign reference from finetune data\n",
    "finetune_benign = finetune_data['benign'].cpu().numpy()\n",
    "benign_ref_indices = np.random.choice(len(finetune_benign), size=2000, replace=False)\n",
    "benign_ref = torch.tensor(finetune_benign[benign_ref_indices], dtype=torch.float32).to(DEVICE)\n",
    "\n",
    "# Test sets\n",
    "remaining_indices = np.setdiff1d(np.arange(len(finetune_benign)), benign_ref_indices)\n",
    "benign_test = torch.tensor(finetune_benign[remaining_indices[:2500]], dtype=torch.float32).to(DEVICE)\n",
    "attack_test = torch.tensor(finetune_data['attack'].cpu().numpy()[:312], dtype=torch.float32).to(DEVICE)\n",
    "\n",
    "print(\"Preparing test set...\")\n",
    "print(f\"   Benign reference: {len(benign_ref)}\")\n",
    "print(f\"   Benign test: {len(benign_test)}\")\n",
    "print(f\"   Attack test: {len(attack_test)}\\n\")\n",
    "\n",
    "print(\"ğŸ§  Encoding samples...\")\n",
    "with torch.no_grad():\n",
    "    ref_encodings = encoder(benign_ref).cpu().numpy()\n",
    "    test_encodings = torch.cat([\n",
    "        encoder(benign_test),\n",
    "        encoder(attack_test)\n",
    "    ]).cpu().numpy()\n",
    "\n",
    "print(f\"   âœ… Encodings computed\")\n",
    "print(f\"      Reference: {ref_encodings.shape}\")\n",
    "print(f\"      Test: {test_encodings.shape}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fa5601",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Computing anomaly scores...\\n\")\n",
    "\n",
    "# Normalize\n",
    "ref_norm = ref_encodings / (np.linalg.norm(ref_encodings, axis=1, keepdims=True) + 1e-8)\n",
    "test_norm = test_encodings / (np.linalg.norm(test_encodings, axis=1, keepdims=True) + 1e-8)\n",
    "\n",
    "# Score: similarity to top-10 closest references\n",
    "scores = np.zeros(len(test_norm))\n",
    "for i, test_vec in enumerate(test_norm):\n",
    "    sims = np.dot(ref_norm, test_vec)\n",
    "    scores[i] = -np.mean(np.sort(sims)[-10:])  # Negative because lower is more anomalous\n",
    "\n",
    "# Labels\n",
    "y_true = np.concatenate([np.zeros(len(benign_test)), np.ones(len(attack_test))])\n",
    "\n",
    "# AUC\n",
    "auc = roc_auc_score(y_true, scores)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(f\"ğŸ¯ UNSUPERVISED AUC: {auc:.4f}\".center(70))\n",
    "print(\"=\"*70)\n",
    "\n",
    "if auc >= 0.7:\n",
    "    print(\"\\nâœ… Excellent - AUC >= 0.7\")\n",
    "elif auc >= 0.6:\n",
    "    print(\"\\nâš ï¸ Good - AUC >= 0.6\")\n",
    "elif auc >= 0.5:\n",
    "    print(\"\\nâš ï¸ Moderate - AUC >= 0.5\")\n",
    "else:\n",
    "    print(\"\\nâŒ Poor - AUC < 0.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d69d94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ“‹ FINAL SUMMARY\".center(70))\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nâœ… COMPLETE!\")\n",
    "\n",
    "print(f\"\\nğŸ“ Weights:\")\n",
    "print(f\"   {final_weight_path}\")\n",
    "if os.path.exists(final_weight_path):\n",
    "    size_mb = os.path.getsize(final_weight_path) / 1e6\n",
    "    print(f\"   Size: {size_mb:.0f} MB\")\n",
    "\n",
    "print(f\"\\nğŸ¯ Performance:\")\n",
    "print(f\"   Unsupervised AUC: {auc:.4f}\")\n",
    "if SKIP_TRAINING:\n",
    "    print(f\"   Training Status: SKIPPED âœ… (Weights loaded)\")\n",
    "    print(f\"   Time Saved: ~30 minutes â­ï¸\")\n",
    "else:\n",
    "    print(f\"   Training Status: FRESH TRAINED\")\n",
    "\n",
    "print(f\"\\nğŸ’¡ Key Answer to Your Question:\")\n",
    "print(f\"   â“ Why 30 mins if we have weights?\")\n",
    "print(f\"   âœ… Answer: We don't! This notebook detects weights and loads them instantly!\")\n",
    "\n",
    "print(f\"\\nâœ¨ Absolute Path Solution:\")\n",
    "print(f\"   âœ… All paths are absolute (no more ../../../)\")\n",
    "print(f\"   âœ… Works from any subdirectory\")\n",
    "print(f\"   âœ… No relative path breaking\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"âœ… PIPELINE COMPLETE!\".center(70))\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f3c244",
   "metadata": {},
   "source": [
    "# SSL Pretraining - Why 30 mins when we have weights?\n",
    "\n",
    "## Smart Pipeline: Check â†’ Load OR Train â†’ Evaluate\n",
    "\n",
    "**The Question You Asked:**\n",
    "- â“ \"Why would training take 30 mins if we already have pretrained weights?\"\n",
    "- âœ… Answer: It shouldn't! This notebook detects existing weights and loads them.\n",
    "\n",
    "**Existing Weights Found:**\n",
    "- ğŸ“ `/thesis_final/weights/ssl/bimamba_masking_ssl_final.pth` (14 MB)\n",
    "- â° Saved: Feb 17, 19:30\n",
    "- âœ… Status: READY TO LOAD (skip training!)\n",
    "\n",
    "**Result You Mentioned:**\n",
    "- Your AUC: 0.95 (excellent!)\n",
    "- Environment: 0.1008 (will recalculate below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c77f748d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "STAGE 0: IMPORTS & SETUP\n",
      "======================================================================\n",
      "âœ… Mamba imported\n",
      "âœ… Device: cuda\n",
      "   GPU: NVIDIA GeForce RTX 4070 Ti SUPER\n",
      "   VRAM: 16.7 GB\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"STAGE 0: IMPORTS & SETUP\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "import os, sys, pickle, numpy as np, torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "try:\n",
    "    from mamba_ssm import Mamba\n",
    "    print(\"âœ… Mamba imported\")\n",
    "except:\n",
    "    os.system('pip install mamba-ssm -q')\n",
    "    from mamba_ssm import Mamba\n",
    "    print(\"âœ… Mamba installed & imported\")\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"âœ… Device: {DEVICE}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"   VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3678f5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STAGE 1: PATHS & DATA\n",
      "======================================================================\n",
      "\n",
      "ğŸ“‚ Loading data...\n",
      "âœ… Pretrain: 787,004 flows\n",
      "âœ… Finetune: 834,241 flows\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STAGE 1: PATHS & DATA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "WORKSPACE = \"/home/T2510596/Downloads/totally fresh\"\n",
    "WEIGHTS_DIR = os.path.join(WORKSPACE, \"thesis_final/weights/ssl\")\n",
    "DATA_DIR = os.path.join(WORKSPACE, \"Organized_Final/data/unswnb15_full\")\n",
    "PRETRAIN_PKL = os.path.join(DATA_DIR, \"pretrain_50pct_benign.pkl\")\n",
    "FINETUNE_PKL = os.path.join(DATA_DIR, \"finetune_mixed.pkl\")\n",
    "final_weight_path = os.path.join(WEIGHTS_DIR, \"bimamba_masking_ssl_final.pth\")\n",
    "\n",
    "print(f\"\\nğŸ“‚ Loading data...\")\n",
    "with open(PRETRAIN_PKL, 'rb') as f:\n",
    "    pretrain_data = pickle.load(f)\n",
    "with open(FINETUNE_PKL, 'rb') as f:\n",
    "    finetune_data = pickle.load(f)\n",
    "\n",
    "print(f\"âœ… Pretrain: {len(pretrain_data):,} flows\")\n",
    "print(f\"âœ… Finetune: {len(finetune_data):,} flows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0fe3449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STAGE 2: MODEL DEFINITION\n",
      "======================================================================\n",
      "âœ… Models defined\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STAGE 2: MODEL DEFINITION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "class PacketEmbedder(nn.Module):\n",
    "    def __init__(self, d_model=256):\n",
    "        super().__init__()\n",
    "        self.emb_proto = nn.Embedding(256, 32)\n",
    "        self.emb_flags = nn.Embedding(64, 32)\n",
    "        self.emb_dir = nn.Embedding(2, 8)\n",
    "        self.proj_len = nn.Linear(1, 32)\n",
    "        self.proj_iat = nn.Linear(1, 32)\n",
    "        self.fusion = nn.Linear(136, d_model)\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        proto = x[:,:,0].long().clamp(0, 255)\n",
    "        length = x[:,:,1:2]\n",
    "        flags = x[:,:,2].long().clamp(0, 63)\n",
    "        iat = x[:,:,3:4]\n",
    "        direction = x[:,:,4].long().clamp(0, 1)\n",
    "        \n",
    "        e_p = self.emb_proto(proto)\n",
    "        e_f = self.emb_flags(flags)\n",
    "        e_d = self.emb_dir(direction)\n",
    "        e_l = self.proj_len(length)\n",
    "        e_i = self.proj_iat(iat)\n",
    "        \n",
    "        cat = torch.cat([e_p, e_f, e_d, e_l, e_i], dim=-1)\n",
    "        return self.norm(self.fusion(cat))\n",
    "\n",
    "class BiMambaEncoder(nn.Module):\n",
    "    def __init__(self, d_model=256, n_layers=4):\n",
    "        super().__init__()\n",
    "        self.tokenizer = PacketEmbedder(d_model)\n",
    "        self.layers = nn.ModuleList([Mamba(d_model=d_model, d_state=16, d_conv=4, expand=2) for _ in range(n_layers)])\n",
    "        self.layers_rev = nn.ModuleList([Mamba(d_model=d_model, d_state=16, d_conv=4, expand=2) for _ in range(n_layers)])\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        self.proj_head = nn.Sequential(nn.Linear(d_model, d_model), nn.ReLU(), nn.Linear(d_model, 128))\n",
    "        self.recon_head = nn.Linear(d_model, 5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_emb = self.tokenizer(x)\n",
    "        feat = x_emb\n",
    "        for fwd, bwd in zip(self.layers, self.layers_rev):\n",
    "            out_f = fwd(feat)\n",
    "            feat_rev = torch.flip(feat, dims=[1])\n",
    "            out_b = bwd(feat_rev)\n",
    "            out_b = torch.flip(out_b, dims=[1])\n",
    "            feat = self.norm(out_f + out_b + feat)\n",
    "        z = self.proj_head(feat.mean(dim=1))\n",
    "        recon = self.recon_head(feat)\n",
    "        return z, recon\n",
    "\n",
    "print(\"âœ… Models defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e43d2322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "âš¡ SMART WEIGHT DETECTION âš¡\n",
      "======================================================================\n",
      "\n",
      "ğŸ” Checking: /home/T2510596/Downloads/totally fresh/thesis_final/weights/ssl/bimamba_masking_ssl_final.pth\n",
      "\n",
      "âœ… WEIGHTS FOUND (15 MB)!\n",
      "\n",
      "ğŸš€ LOADING WEIGHTS (skipping 30-minute training!)\n",
      "\n",
      "â±ï¸ Time saved: ~30 minutes â­ï¸\n",
      "\n",
      "âœ… Model loaded: 3,648,533 parameters\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âš¡ SMART WEIGHT DETECTION âš¡\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nğŸ” Checking: {final_weight_path}\")\n",
    "\n",
    "if os.path.exists(final_weight_path):\n",
    "    size_mb = os.path.getsize(final_weight_path) / 1e6\n",
    "    print(f\"\\nâœ… WEIGHTS FOUND ({size_mb:.0f} MB)!\")\n",
    "    print(f\"\\nğŸš€ LOADING WEIGHTS (skipping 30-minute training!)\")\n",
    "    print(f\"\\nâ±ï¸ Time saved: ~30 minutes â­ï¸\")\n",
    "    \n",
    "    encoder = BiMambaEncoder(d_model=256, n_layers=4).to(DEVICE)\n",
    "    encoder.load_state_dict(torch.load(final_weight_path, map_location=DEVICE, weights_only=False))\n",
    "    encoder.eval()\n",
    "    \n",
    "    params = sum(p.numel() for p in encoder.parameters())\n",
    "    print(f\"\\nâœ… Model loaded: {params:,} parameters\")\n",
    "    SKIP_TRAINING = True\n",
    "else:\n",
    "    print(f\"\\nâŒ Weights not found\")\n",
    "    print(f\"Training will be needed (~30 mins)\")\n",
    "    SKIP_TRAINING = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41fe399a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STAGE 3: ANOMALY DETECTION EVAL\n",
      "======================================================================\n",
      "\n",
      "Preparing test set...\n",
      "   Benign reference: 2,000\n",
      "   Benign test: 2,500\n",
      "   Attack test: 312\n",
      "\n",
      "ğŸ§  Encoding samples...\n",
      "   âœ… Encodings computed\n",
      "      Reference: (2000, 128)\n",
      "      Test: (2812, 128)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STAGE 3: ANOMALY DETECTION EVAL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nPreparing test set...\")\n",
    "test_sample = finetune_data[:5000]\n",
    "benign_test = [d for d in test_sample if d['label'] == 0][:2500]\n",
    "attack_test = [d for d in test_sample if d['label'] == 1][:2500]\n",
    "\n",
    "test_flows = benign_test + attack_test\n",
    "test_labels = [0]*len(benign_test) + [1]*len(attack_test)\n",
    "benign_ref = pretrain_data[:2000]\n",
    "\n",
    "print(f\"   Benign reference: {len(benign_ref):,}\")\n",
    "print(f\"   Benign test: {len(benign_test):,}\")\n",
    "print(f\"   Attack test: {len(attack_test):,}\")\n",
    "\n",
    "print(\"\\nğŸ§  Encoding samples...\")\n",
    "with torch.no_grad():\n",
    "    # Reference\n",
    "    ref_reps = []\n",
    "    for i in range(0, len(benign_ref), 256):\n",
    "        batch = benign_ref[i:i+256]\n",
    "        feats = np.stack([d['features'] if isinstance(d, dict) else d for d in batch])\n",
    "        x = torch.from_numpy(feats).float().to(DEVICE)\n",
    "        z, _ = encoder(x)\n",
    "        ref_reps.append(z.cpu().numpy())\n",
    "    ref_reps = np.concatenate(ref_reps, axis=0)\n",
    "    ref_reps = ref_reps / (np.linalg.norm(ref_reps, axis=1, keepdims=True) + 1e-8)\n",
    "    \n",
    "    # Test\n",
    "    test_reps = []\n",
    "    for i in range(0, len(test_flows), 256):\n",
    "        batch = test_flows[i:i+256]\n",
    "        feats = np.stack([d['features'] if isinstance(d, dict) else d for d in batch])\n",
    "        x = torch.from_numpy(feats).float().to(DEVICE)\n",
    "        z, _ = encoder(x)\n",
    "        test_reps.append(z.cpu().numpy())\n",
    "    test_reps = np.concatenate(test_reps, axis=0)\n",
    "    test_reps = test_reps / (np.linalg.norm(test_reps, axis=1, keepdims=True) + 1e-8)\n",
    "    \n",
    "    print(f\"   âœ… Encodings computed\")\n",
    "    print(f\"      Reference: {ref_reps.shape}\")\n",
    "    print(f\"      Test: {test_reps.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01d26364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing anomaly scores...\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ref_encodings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mComputing anomaly scores...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Normalize\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m ref_norm = \u001b[43mref_encodings\u001b[49m / (np.linalg.norm(ref_encodings, axis=\u001b[32m1\u001b[39m, keepdims=\u001b[38;5;28;01mTrue\u001b[39;00m) + \u001b[32m1e-8\u001b[39m)\n\u001b[32m      5\u001b[39m test_norm = test_encodings / (np.linalg.norm(test_encodings, axis=\u001b[32m1\u001b[39m, keepdims=\u001b[38;5;28;01mTrue\u001b[39;00m) + \u001b[32m1e-8\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Score: higher for anomalies (low similarity to benign reference)\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'ref_encodings' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Computing anomaly scores...\\n\")\n",
    "\n",
    "# Normalize\n",
    "ref_norm = ref_encodings / (np.linalg.norm(ref_encodings, axis=1, keepdims=True) + 1e-8)\n",
    "test_norm = test_encodings / (np.linalg.norm(test_encodings, axis=1, keepdims=True) + 1e-8)\n",
    "\n",
    "# Score: higher for anomalies (low similarity to benign reference)\n",
    "scores = np.zeros(len(test_norm))\n",
    "for i, test_vec in enumerate(test_norm):\n",
    "    sims = np.dot(ref_norm, test_vec)\n",
    "    # FIX: Invert so anomalies get high scores\n",
    "    # Use 1 - similarity so low similarity to benign = high anomaly score\n",
    "    scores[i] = 1.0 - np.mean(np.sort(sims)[-10:])\n",
    "\n",
    "# Labels: 0=benign, 1=anomaly\n",
    "y_true = np.concatenate([np.zeros(len(benign_test)), np.ones(len(attack_test))])\n",
    "\n",
    "# AUC\n",
    "auc = roc_auc_score(y_true, scores)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(f\"ğŸ¯ UNSUPERVISED AUC (CORRECTED): {auc:.4f}\".center(70))\n",
    "print(\"=\"*70)\n",
    "\n",
    "if auc >= 0.7:\n",
    "    print(\"\\nâœ… Excellent - AUC >= 0.7\")\n",
    "elif auc >= 0.6:\n",
    "    print(\"\\nâš ï¸ Good - AUC >= 0.6\")\n",
    "elif auc >= 0.5:\n",
    "    print(\"\\nâš ï¸ Moderate - AUC >= 0.5\")\n",
    "else:\n",
    "    print(\"\\nâŒ Poor - AUC < 0.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5848dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ“‹ FINAL SUMMARY\n",
      "======================================================================\n",
      "\n",
      "âœ… COMPLETE!\n",
      "\n",
      "ğŸ“ Weights:\n",
      "   /home/T2510596/Downloads/totally fresh/thesis_final/weights/ssl/bimamba_masking_ssl_final.pth\n",
      "   Size: 15 MB\n",
      "\n",
      "ğŸ¯ Performance:\n",
      "   Unsupervised AUC: 0.1008\n",
      "   Training Status: SKIPPED âœ… (Weights loaded)\n",
      "   Time Saved: ~30 minutes â­ï¸\n",
      "\n",
      "ğŸ’¡ Key Answer to Your Question:\n",
      "   â“ Why 30 mins if we have weights?\n",
      "   âœ… Answer: We don't! This notebook detects weights and loads them instantly!\n",
      "\n",
      "âœ¨ Absolute Path Solution:\n",
      "   âœ… All paths are absolute (no more ../../../)\n",
      "   âœ… Works from any subdirectory\n",
      "   âœ… No relative path breaking\n",
      "\n",
      "======================================================================\n",
      "âœ… PIPELINE COMPLETE!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nComputing anomaly scores...\")\n",
    "with torch.no_grad():\n",
    "    scores = []\n",
    "    for i in range(0, len(test_reps), 200):\n",
    "        chunk = test_reps[i:i+200]\n",
    "        sim = chunk @ ref_reps.T\n",
    "        topk = np.sort(sim, axis=1)[:, -10:]\n",
    "        # FIX: High similarity to benign = low anomaly score\n",
    "        #      Low similarity to benign = high anomaly score\n",
    "        # Use 1 - similarity so anomalies get high scores\n",
    "        scores.extend((1.0 - topk.mean(axis=1)).tolist())\n",
    "    \n",
    "    auc = roc_auc_score(test_labels, scores)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"ğŸ¯ UNSUPERVISED AUC (CORRECTED): {auc:.4f}\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "if auc > 0.85:\n",
    "    print(f\"\\nâœ¨ Excellent! AUC > 0.85\")\n",
    "elif auc > 0.75:\n",
    "    print(f\"\\nâœ… Good! AUC > 0.75\")\n",
    "elif auc > 0.5:\n",
    "    print(f\"\\nâš ï¸ Fair - AUC > 0.5 (random is 0.5)\")\n",
    "else:\n",
    "    print(f\"\\nâŒ Poor - AUC < 0.5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebf9615",
   "metadata": {},
   "source": [
    "# Complete End-to-End SSL Pretraining Pipeline\n",
    "\n",
    "From Preprocessed Flows â†’ BiMamba Encoder â†’ NT-Xent Contrastive Loss\n",
    "\n",
    "**Features:**\n",
    "- âœ… Checkpoint after each stage\n",
    "- âœ… Resume from interruptions\n",
    "- âœ… Skip already-completed stages\n",
    "- âœ… Full logging\n",
    "- âœ… Anti-shortcut masking augmentation (50% LogLen, 30% Flags, 0% LogIAT)\n",
    "\n",
    "**Date:** February 17, 2026"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7372e8",
   "metadata": {},
   "source": [
    "## Stage 0: Setup & Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9373393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Core imports complete\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from collections import Counter\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"âœ… Core imports complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d007cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Mamba SSM imported\n"
     ]
    }
   ],
   "source": [
    "# Mamba-SSM for state space models\n",
    "try:\n",
    "    from mamba_ssm import Mamba\n",
    "    print(\"âœ… Mamba SSM imported\")\n",
    "except ImportError:\n",
    "    print(\"âŒ Missing mamba_ssm. Install: pip install mamba-ssm\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502b70d2",
   "metadata": {},
   "source": [
    "## Stage 1: GPU Detection & Device Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8db4bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Device: cuda\n",
      "GPU: NVIDIA GeForce RTX 4070 Ti SUPER\n",
      "VRAM: 16.7 GB\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Device: {DEVICE}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "print(f\"{'='*70}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a63c5d",
   "metadata": {},
   "source": [
    "## Stage 2: Path Configuration (Absolute Paths Fix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0197f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Paths configured\n",
      "   Data: /home/T2510596/Downloads/totally fresh/Organized_Final/data/unswnb15_full\n",
      "   Weights: /home/T2510596/Downloads/totally fresh/thesis_final/weights/ssl\n",
      "   Logs: /home/T2510596/Downloads/totally fresh/thesis_final/results_ssl_pipeline/logs\n",
      "\n",
      "âœ… Pretrain: 582 MB\n",
      "âœ… Finetune: 617 MB\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION TO PATH ISSUE:\n",
    "# All paths are absolute, rooted at WORKSPACE_ROOT\n",
    "# Works from any subdirectory without breaking relative path chains\n",
    "\n",
    "WORKSPACE_ROOT = \"/home/T2510596/Downloads/totally fresh\"\n",
    "ORGANIZED_FINAL = os.path.join(WORKSPACE_ROOT, \"Organized_Final\")\n",
    "THESIS_FINAL = os.path.join(WORKSPACE_ROOT, \"thesis_final\")\n",
    "\n",
    "DATA_DIR = os.path.join(ORGANIZED_FINAL, \"data\", \"unswnb15_full\")\n",
    "PRETRAIN_PKL = os.path.join(DATA_DIR, \"pretrain_50pct_benign.pkl\")\n",
    "FINETUNE_PKL = os.path.join(DATA_DIR, \"finetune_mixed.pkl\")\n",
    "\n",
    "OUTPUT_DIR = os.path.join(THESIS_FINAL, \"results_ssl_pipeline\")\n",
    "WEIGHTS_DIR = os.path.join(THESIS_FINAL, \"weights\", \"ssl\")\n",
    "LOGS_DIR = os.path.join(OUTPUT_DIR, \"logs\")\n",
    "\n",
    "for d in [OUTPUT_DIR, WEIGHTS_DIR, LOGS_DIR]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "print(\"ğŸ“ Paths configured\")\n",
    "print(f\"   Data: {DATA_DIR}\")\n",
    "print(f\"   Weights: {WEIGHTS_DIR}\")\n",
    "print(f\"   Logs: {LOGS_DIR}\\n\")\n",
    "\n",
    "# Verify data exists\n",
    "for fpath, fname in [(PRETRAIN_PKL, \"Pretrain\"), (FINETUNE_PKL, \"Finetune\")]:\n",
    "    if os.path.exists(fpath):\n",
    "        size_mb = os.path.getsize(fpath) / 1e6\n",
    "        print(f\"âœ… {fname}: {size_mb:.0f} MB\")\n",
    "    else:\n",
    "        print(f\"âŒ {fname}: NOT FOUND at {fpath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e68441f",
   "metadata": {},
   "source": [
    "## Stage 3: Load Preprocessed Flow Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10ba9b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STAGE 3: Load Preprocessed Flow Data\n",
      "======================================================================\n",
      "ğŸ“‚ Loading pretrain data...\n",
      "âœ… Loaded 787,004 flows\n",
      "\n",
      "Sample flow structure:\n",
      "   Keys: ['features', 'label', 'label_str', 'key']\n",
      "   Features shape: (32, 5)\n",
      "   Label: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*70}\\nSTAGE 3: Load Preprocessed Flow Data\\n{'='*70}\")\n",
    "\n",
    "print(\"ğŸ“‚ Loading pretrain data...\")\n",
    "with open(PRETRAIN_PKL, 'rb') as f:\n",
    "    pretrain_data = pickle.load(f)\n",
    "\n",
    "print(f\"âœ… Loaded {len(pretrain_data):,} flows\")\n",
    "print(f\"\\nSample flow structure:\")\n",
    "if isinstance(pretrain_data[0], dict):\n",
    "    print(f\"   Keys: {list(pretrain_data[0].keys())}\")\n",
    "    print(f\"   Features shape: {pretrain_data[0]['features'].shape}\")\n",
    "    print(f\"   Label: {pretrain_data[0]['label']}\")\n",
    "else:\n",
    "    print(f\"   Type: {type(pretrain_data[0])}\")\n",
    "    print(f\"   Shape: {pretrain_data[0].shape if hasattr(pretrain_data[0], 'shape') else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36854fb",
   "metadata": {},
   "source": [
    "## Stage 4: Define Model Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bec3dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STAGE 4: Define Model Architectures\n",
      "======================================================================\n",
      "âœ… PacketEmbedder defined\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*70}\\nSTAGE 4: Define Model Architectures\\n{'='*70}\")\n",
    "\n",
    "class PacketEmbedder(nn.Module):\n",
    "    \"\"\"Embed 5 packet features [Proto, LogLen, Flags, LogIAT, Direction] â†’ 256-d\"\"\"\n",
    "    def __init__(self, d_model=256):\n",
    "        super().__init__()\n",
    "        self.emb_proto = nn.Embedding(256, 32)  # Protocol: 0-255 â†’ 32-d\n",
    "        self.emb_flags = nn.Embedding(64, 32)   # Flags: 0-63 â†’ 32-d\n",
    "        self.emb_dir = nn.Embedding(2, 8)       # Direction: 0-1 â†’ 8-d\n",
    "        self.proj_len = nn.Linear(1, 32)        # LogLen: 1-d â†’ 32-d\n",
    "        self.proj_iat = nn.Linear(1, 32)        # LogIAT: 1-d â†’ 32-d\n",
    "        # Total: 32+32+8+32+32 = 136-d â†’ fuse to 256-d\n",
    "        self.fusion = nn.Linear(136, d_model)\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (B, T, 5) where B=batch, T=seq_len, 5=features\n",
    "        proto = x[:,:,0].long().clamp(0, 255)\n",
    "        length = x[:,:,1:2]\n",
    "        flags = x[:,:,2].long().clamp(0, 63)\n",
    "        iat = x[:,:,3:4]\n",
    "        direction = x[:,:,4].long().clamp(0, 1)\n",
    "        \n",
    "        e_p = self.emb_proto(proto)    # (B, T, 32)\n",
    "        e_f = self.emb_flags(flags)    # (B, T, 32)\n",
    "        e_d = self.emb_dir(direction)  # (B, T, 8)\n",
    "        e_l = self.proj_len(length)    # (B, T, 32)\n",
    "        e_i = self.proj_iat(iat)       # (B, T, 32)\n",
    "        \n",
    "        cat = torch.cat([e_p, e_f, e_d, e_l, e_i], dim=-1)  # (B, T, 136)\n",
    "        return self.norm(self.fusion(cat))  # (B, T, 256)\n",
    "\n",
    "print(\"âœ… PacketEmbedder defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "821bc0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… BiMambaEncoder defined\n"
     ]
    }
   ],
   "source": [
    "class BiMambaEncoder(nn.Module):\n",
    "    \"\"\"Bidirectional Mamba encoder with contrastive projection head\"\"\"\n",
    "    def __init__(self, d_model=256, n_layers=4):\n",
    "        super().__init__()\n",
    "        self.tokenizer = PacketEmbedder(d_model)\n",
    "        \n",
    "        # Bidirectional layers\n",
    "        self.layers = nn.ModuleList([\n",
    "            Mamba(d_model=d_model, d_state=16, d_conv=4, expand=2)\n",
    "            for _ in range(n_layers)\n",
    "        ])\n",
    "        self.layers_rev = nn.ModuleList([\n",
    "            Mamba(d_model=d_model, d_state=16, d_conv=4, expand=2)\n",
    "            for _ in range(n_layers)\n",
    "        ])\n",
    "        \n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        \n",
    "        # Contrastive projection head\n",
    "        self.proj_head = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_model, 128)  # Project to 128-d for NT-Xent\n",
    "        )\n",
    "        \n",
    "        # Reconstruction head (for auxiliary loss, optional)\n",
    "        self.recon_head = nn.Linear(d_model, 5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_emb = self.tokenizer(x)  # (B, T, 256)\n",
    "        feat = x_emb\n",
    "        \n",
    "        # Bidirectional processing\n",
    "        for fwd, bwd in zip(self.layers, self.layers_rev):\n",
    "            out_f = fwd(feat)                              # Forward\n",
    "            feat_rev = torch.flip(feat, dims=[1])          # Reverse sequence\n",
    "            out_b = bwd(feat_rev)                          # Backward\n",
    "            out_b = torch.flip(out_b, dims=[1])            # Flip back\n",
    "            feat = self.norm(out_f + out_b + feat)         # Residual + fuse\n",
    "        \n",
    "        # Global representation (mean pooling)\n",
    "        global_rep = feat.mean(dim=1)  # (B, 256)\n",
    "        \n",
    "        z = self.proj_head(global_rep)  # (B, 128) - for contrastive loss\n",
    "        recon = self.recon_head(feat)   # (B, T, 5) - reconstruction\n",
    "        \n",
    "        return z, recon\n",
    "\n",
    "print(\"âœ… BiMambaEncoder defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "319139e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… BiMambaEncoder: 3,648,533 parameters (~3.6M)\n",
      "   Input: torch.Size([2, 32, 5])\n",
      "   Contrastive output (z): torch.Size([2, 128])\n",
      "   Reconstruction output: torch.Size([2, 32, 5])\n",
      "   âœ… Architecture test passed\n"
     ]
    }
   ],
   "source": [
    "# Test model architecture\n",
    "model_test = BiMambaEncoder(d_model=256, n_layers=4).to(DEVICE)\n",
    "params = sum(p.numel() for p in model_test.parameters())\n",
    "print(f\"âœ… BiMambaEncoder: {params:,} parameters (~{params/1e6:.1f}M)\")\n",
    "\n",
    "# Test forward pass\n",
    "x_dummy = torch.randn(2, 32, 5).to(DEVICE)  # Move to device\n",
    "z, recon = model_test(x_dummy)\n",
    "print(f\"   Input: {x_dummy.shape}\")\n",
    "print(f\"   Contrastive output (z): {z.shape}\")\n",
    "print(f\"   Reconstruction output: {recon.shape}\")\n",
    "print(f\"   âœ… Architecture test passed\")\n",
    "del model_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbba45aa",
   "metadata": {},
   "source": [
    "## Stage 5: Anti-Shortcut Masking Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e59517be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STAGE 5: Anti-Shortcut Masking Augmentation\n",
      "======================================================================\n",
      "âœ… AntiShortcutAugmentation class defined\n",
      "\n",
      "   Original shape: (32, 5)\n",
      "   Augmented shape: (32, 5)\n",
      "   Columns masked (showing sparsity):\n",
      "      Col 0: 0.0%\n",
      "      Col 1: 0.0%\n",
      "      Col 2: 0.0%\n",
      "      Col 3: 0.0%\n",
      "      Col 4: 0.0%\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*70}\\nSTAGE 5: Anti-Shortcut Masking Augmentation\\n{'='*70}\")\n",
    "\n",
    "class AntiShortcutAugmentation:\n",
    "    \"\"\"\n",
    "    Selective masking to prevent model from learning shortcuts:\n",
    "    - Pro(col 0): 20% mask rate\n",
    "    - LogLen(col 1): 50% mask rate â† PRIMARY DISCRIMINATOR\n",
    "    - Flags(col 2): 30% mask rate\n",
    "    - LogIAT(col 3): 0% mask rate â† NEVER mask (temporal dynamics)\n",
    "    - Direction(col 4): 10% mask rate\n",
    "    \n",
    "    Plus jitter on LogIAT to simulate timing noise.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.mask_probs = {\n",
    "            0: 0.20,  # Proto\n",
    "            1: 0.50,  # LogLen (HEAVY!)\n",
    "            2: 0.30,  # Flags\n",
    "            3: 0.00,  # LogIAT (NEVER mask)\n",
    "            4: 0.10,  # Dir\n",
    "        }\n",
    "        self.jitter_scale = 0.05\n",
    "    \n",
    "    def __call__(self, features):\n",
    "        \"\"\"Apply masking to features (numpy array, shape=(T,5))\"\"\"\n",
    "        aug = features.copy()\n",
    "        \n",
    "        # Apply column-wise masking\n",
    "        for col, prob in self.mask_probs.items():\n",
    "            if prob > 0 and np.random.random() < prob:\n",
    "                aug[:, col] = 0.0\n",
    "        \n",
    "        # Jitter on LogIAT to simulate timing variations\n",
    "        aug[:, 3] += np.random.randn(aug.shape[0]) * self.jitter_scale\n",
    "        \n",
    "        return aug\n",
    "\n",
    "print(\"âœ… AntiShortcutAugmentation class defined\")\n",
    "\n",
    "# Test augmentation\n",
    "aug = AntiShortcutAugmentation()\n",
    "features_test = np.random.randn(32, 5)\n",
    "features_aug = aug(features_test)\n",
    "print(f\"\\n   Original shape: {features_test.shape}\")\n",
    "print(f\"   Augmented shape: {features_aug.shape}\")\n",
    "print(f\"   Columns masked (showing sparsity):\")\n",
    "for col in range(5):\n",
    "    sparsity = (features_aug[:, col] == 0).sum() / len(features_aug)\n",
    "    print(f\"      Col {col}: {sparsity:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d566272c",
   "metadata": {},
   "source": [
    "## Stage 6: Contrastive Dataset & Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83e39399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ContrastiveDataset defined\n"
     ]
    }
   ],
   "source": [
    "class ContrastiveDataset(Dataset):\n",
    "    \"\"\"Returns (x_original, x_augmented) pairs for NT-Xent loss\"\"\"\n",
    "    def __init__(self, data, augmentor):\n",
    "        self.data = data\n",
    "        self.augmentor = augmentor\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data[idx]\n",
    "        # Handle both dict and array formats\n",
    "        f = row['features'] if isinstance(row, dict) else row\n",
    "        \n",
    "        # Original\n",
    "        x = torch.from_numpy(f).float()\n",
    "        \n",
    "        # Augmented\n",
    "        x_aug = torch.from_numpy(self.augmentor(f)).float()\n",
    "        \n",
    "        return x, x_aug\n",
    "\n",
    "print(\"âœ… ContrastiveDataset defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f8d0654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STAGE 6: NT-Xent Contrastive Loss\n",
      "======================================================================\n",
      "âœ… NT-Xent loss function defined\n",
      "   Test loss: 2.0908 âœ…\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*70}\\nSTAGE 6: NT-Xent Contrastive Loss\\n{'='*70}\")\n",
    "\n",
    "def nt_xent_loss(z_i, z_j, temperature=0.5):\n",
    "    \"\"\"\n",
    "    Normalized Temperature-scaled Cross Entropy Loss\n",
    "    From SimCLR paper.\n",
    "    \n",
    "    Args:\n",
    "        z_i: Projections from augmented view 1, shape (B, d)\n",
    "        z_j: Projections from augmented view 2, shape (B, d)\n",
    "        temperature: Scaling factor (lower = sharper distribution)\n",
    "    \n",
    "    Returns:\n",
    "        loss: Scalar contrastive loss\n",
    "    \"\"\"\n",
    "    # Normalize on unit sphere\n",
    "    z_i = F.normalize(z_i, dim=1)\n",
    "    z_j = F.normalize(z_j, dim=1)\n",
    "    \n",
    "    # Cosine similarity matrix\n",
    "    logits = torch.matmul(z_i, z_j.T) / temperature  # (B, B)\n",
    "    \n",
    "    # Labels are identity: sample i should match with sample i\n",
    "    labels = torch.arange(z_i.size(0), device=z_i.device)\n",
    "    \n",
    "    # Cross entropy\n",
    "    return F.cross_entropy(logits, labels)\n",
    "\n",
    "print(\"âœ… NT-Xent loss function defined\")\n",
    "\n",
    "# Test loss\n",
    "z_test = torch.randn(8, 128)\n",
    "z_aug_test = torch.randn(8, 128)\n",
    "loss_test = nt_xent_loss(z_test, z_aug_test)\n",
    "print(f\"   Test loss: {loss_test.item():.4f} âœ…\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e39ab1",
   "metadata": {},
   "source": [
    "## Stage 7: Setup DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "129bd875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STAGE 7: Prepare Data for Training\n",
      "======================================================================\n",
      "âœ… DataLoader ready\n",
      "   Total flows: 787,004\n",
      "   Batch size: 64\n",
      "   Batches per epoch: 12,297\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*70}\\nSTAGE 7: Prepare Data for Training\\n{'='*70}\")\n",
    "\n",
    "augmentor = AntiShortcutAugmentation()\n",
    "pretrain_dataset = ContrastiveDataset(pretrain_data, augmentor)\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "pretrain_loader = DataLoader(\n",
    "    pretrain_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"âœ… DataLoader ready\")\n",
    "print(f\"   Total flows: {len(pretrain_dataset):,}\")\n",
    "print(f\"   Batch size: {BATCH_SIZE}\")\n",
    "print(f\"   Batches per epoch: {len(pretrain_loader):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3c1a3d",
   "metadata": {},
   "source": [
    "## Stage 8: SSL Pretraining with Checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2d7fcae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STAGE 8: SSL Pretraining with Checkpointing\n",
      "======================================================================\n",
      "âœ… Config:\n",
      "   Epochs: 3\n",
      "   Learning Rate: 0.0005\n",
      "   Temperature: 0.5\n",
      "   Batch Size: 64\n",
      "   Log file: /home/T2510596/Downloads/totally fresh/thesis_final/results_ssl_pipeline/logs/ssl_pretraining.log\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*70}\\nSTAGE 8: SSL Pretraining with Checkpointing\\n{'='*70}\")\n",
    "\n",
    "SSL_EPOCHS = 3\n",
    "LR = 5e-4\n",
    "TEMPERATURE = 0.5\n",
    "\n",
    "# Initialize logging\n",
    "log_file = os.path.join(LOGS_DIR, \"ssl_pretraining.log\")\n",
    "with open(log_file, 'w') as f:\n",
    "    f.write(f\"SSL Pretraining Log\\n\")\n",
    "    f.write(f\"Started: {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "    f.write(f\"Config: Epochs={SSL_EPOCHS}, LR={LR}, Batch={BATCH_SIZE}, Temp={TEMPERATURE}\\n\")\n",
    "    f.write(f\"Data: {len(pretrain_data):,} flows\\n\")\n",
    "    f.write(\"=\"*70 + \"\\n\\n\")\n",
    "\n",
    "print(f\"âœ… Config:\")\n",
    "print(f\"   Epochs: {SSL_EPOCHS}\")\n",
    "print(f\"   Learning Rate: {LR}\")\n",
    "print(f\"   Temperature: {TEMPERATURE}\")\n",
    "print(f\"   Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"   Log file: {log_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ff152a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ†• Starting fresh training...\n",
      "   Starting from epoch 0\n"
     ]
    }
   ],
   "source": [
    "# Check for existing weights (checkpoint logic)\n",
    "final_weight_path = os.path.join(WEIGHTS_DIR, \"bimamba_masking_ssl_final.pth\")\n",
    "last_epoch_file = os.path.join(LOGS_DIR, \"last_epoch.txt\")\n",
    "\n",
    "encoder = BiMambaEncoder(d_model=256, n_layers=4).to(DEVICE)\n",
    "optimizer = torch.optim.AdamW(encoder.parameters(), lr=LR)\n",
    "\n",
    "start_epoch = 0\n",
    "\n",
    "if os.path.exists(final_weight_path):\n",
    "    print(f\"\\nâœ… Final model exists: {final_weight_path}\")\n",
    "    encoder.load_state_dict(torch.load(final_weight_path, map_location=DEVICE, weights_only=False))\n",
    "    print(\"   Skipping training (already complete)\")\n",
    "    start_epoch = SSL_EPOCHS\n",
    "elif os.path.exists(last_epoch_file):\n",
    "    with open(last_epoch_file, 'r') as f:\n",
    "        start_epoch = int(f.read().strip()) + 1\n",
    "    checkpoint_path = os.path.join(WEIGHTS_DIR, f\"bimamba_masking_ssl_epoch_{start_epoch}.pth\")\n",
    "    print(f\"\\nğŸ”„ Resuming from epoch {start_epoch}...\")\n",
    "    encoder.load_state_dict(torch.load(checkpoint_path, map_location=DEVICE, weights_only=False))\n",
    "else:\n",
    "    print(f\"\\nğŸ†• Starting fresh training...\")\n",
    "\n",
    "print(f\"   Starting from epoch {start_epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc6569f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”„ Training epochs 1-3\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Epoch 1/3\n",
      "======================================================================\n",
      "  E1 S  500/12297 | Loss:2.6707 | ETA:5.2m\n",
      "  E1 S 1000/12297 | Loss:2.4915 | ETA:4.9m\n",
      "  E1 S 1500/12297 | Loss:2.6575 | ETA:4.7m\n",
      "  E1 S 2000/12297 | Loss:2.6015 | ETA:4.5m\n",
      "  E1 S 2500/12297 | Loss:2.5495 | ETA:4.3m\n",
      "  E1 S 3000/12297 | Loss:2.7117 | ETA:4.0m\n",
      "  E1 S 3500/12297 | Loss:2.5116 | ETA:3.8m\n",
      "  E1 S 4000/12297 | Loss:2.6507 | ETA:3.6m\n",
      "  E1 S 4500/12297 | Loss:2.6001 | ETA:3.4m\n",
      "  E1 S 5000/12297 | Loss:2.5459 | ETA:3.2m\n",
      "  E1 S 5500/12297 | Loss:2.5161 | ETA:2.9m\n",
      "  E1 S 6000/12297 | Loss:2.6259 | ETA:2.7m\n",
      "  E1 S 6500/12297 | Loss:2.6747 | ETA:2.5m\n",
      "  E1 S 7000/12297 | Loss:2.6410 | ETA:2.3m\n",
      "  E1 S 7500/12297 | Loss:2.6305 | ETA:2.1m\n",
      "  E1 S 8000/12297 | Loss:2.5771 | ETA:1.9m\n",
      "  E1 S 8500/12297 | Loss:2.5930 | ETA:1.6m\n",
      "  E1 S 9000/12297 | Loss:2.5964 | ETA:1.4m\n",
      "  E1 S 9500/12297 | Loss:2.6594 | ETA:1.2m\n",
      "  E1 S10000/12297 | Loss:2.6356 | ETA:1.0m\n",
      "  E1 S10500/12297 | Loss:2.6096 | ETA:0.8m\n",
      "  E1 S11000/12297 | Loss:2.5114 | ETA:0.6m\n",
      "  E1 S11500/12297 | Loss:2.5995 | ETA:0.3m\n",
      "  E1 S12000/12297 | Loss:2.6149 | ETA:0.1m\n",
      "\n",
      "âœ… Epoch 1 complete: avg_loss=2.6230 (5.3m)\n",
      "   ğŸ’¾ Saved: /home/T2510596/Downloads/totally fresh/thesis_final/weights/ssl/bimamba_masking_ssl_epoch_1.pth\n",
      "\n",
      "======================================================================\n",
      "Epoch 2/3\n",
      "======================================================================\n",
      "  E2 S  500/12297 | Loss:2.5632 | ETA:5.1m\n",
      "  E2 S 1000/12297 | Loss:2.6445 | ETA:4.9m\n",
      "  E2 S 1500/12297 | Loss:2.5996 | ETA:4.7m\n",
      "  E2 S 2000/12297 | Loss:2.5833 | ETA:4.4m\n",
      "  E2 S 2500/12297 | Loss:2.7561 | ETA:4.2m\n",
      "  E2 S 3000/12297 | Loss:2.5566 | ETA:4.0m\n",
      "  E2 S 3500/12297 | Loss:2.6353 | ETA:3.8m\n",
      "  E2 S 4000/12297 | Loss:2.6247 | ETA:3.6m\n",
      "  E2 S 4500/12297 | Loss:2.5777 | ETA:3.3m\n",
      "  E2 S 5000/12297 | Loss:2.5136 | ETA:3.1m\n",
      "  E2 S 5500/12297 | Loss:2.5510 | ETA:2.9m\n",
      "  E2 S 6000/12297 | Loss:2.6105 | ETA:2.7m\n",
      "  E2 S 6500/12297 | Loss:2.5429 | ETA:2.5m\n",
      "  E2 S 7000/12297 | Loss:2.6297 | ETA:2.3m\n",
      "  E2 S 7500/12297 | Loss:2.6301 | ETA:2.1m\n",
      "  E2 S 8000/12297 | Loss:2.5781 | ETA:1.8m\n",
      "  E2 S 8500/12297 | Loss:2.5276 | ETA:1.6m\n",
      "  E2 S 9000/12297 | Loss:2.5566 | ETA:1.4m\n",
      "  E2 S 9500/12297 | Loss:2.4919 | ETA:1.2m\n",
      "  E2 S10000/12297 | Loss:2.5985 | ETA:1.0m\n",
      "  E2 S10500/12297 | Loss:2.5984 | ETA:0.8m\n",
      "  E2 S11000/12297 | Loss:2.5956 | ETA:0.6m\n",
      "  E2 S11500/12297 | Loss:2.5850 | ETA:0.3m\n",
      "  E2 S12000/12297 | Loss:2.5752 | ETA:0.1m\n",
      "\n",
      "âœ… Epoch 2 complete: avg_loss=2.5980 (5.3m)\n",
      "   ğŸ’¾ Saved: /home/T2510596/Downloads/totally fresh/thesis_final/weights/ssl/bimamba_masking_ssl_epoch_2.pth\n",
      "\n",
      "======================================================================\n",
      "Epoch 3/3\n",
      "======================================================================\n",
      "  E3 S  500/12297 | Loss:2.5785 | ETA:5.1m\n",
      "  E3 S 1000/12297 | Loss:2.5781 | ETA:4.9m\n",
      "  E3 S 1500/12297 | Loss:2.5445 | ETA:4.7m\n",
      "  E3 S 2000/12297 | Loss:2.6113 | ETA:4.5m\n",
      "  E3 S 2500/12297 | Loss:2.5665 | ETA:4.3m\n",
      "  E3 S 3000/12297 | Loss:2.5041 | ETA:4.0m\n",
      "  E3 S 3500/12297 | Loss:2.4708 | ETA:3.8m\n",
      "  E3 S 4000/12297 | Loss:2.5583 | ETA:3.6m\n",
      "  E3 S 4500/12297 | Loss:2.6128 | ETA:3.4m\n",
      "  E3 S 5000/12297 | Loss:2.4876 | ETA:3.2m\n",
      "  E3 S 5500/12297 | Loss:2.5285 | ETA:3.0m\n",
      "  E3 S 6000/12297 | Loss:2.5825 | ETA:2.7m\n",
      "  E3 S 6500/12297 | Loss:2.5433 | ETA:2.5m\n",
      "  E3 S 7000/12297 | Loss:2.6806 | ETA:2.3m\n",
      "  E3 S 7500/12297 | Loss:2.5609 | ETA:2.2m\n",
      "  E3 S 8000/12297 | Loss:2.5974 | ETA:2.0m\n",
      "  E3 S 8500/12297 | Loss:2.6615 | ETA:1.8m\n",
      "  E3 S 9000/12297 | Loss:2.6859 | ETA:1.5m\n",
      "  E3 S 9500/12297 | Loss:2.6536 | ETA:1.3m\n",
      "  E3 S10000/12297 | Loss:2.5821 | ETA:1.1m\n",
      "  E3 S10500/12297 | Loss:2.6454 | ETA:0.8m\n",
      "  E3 S11000/12297 | Loss:2.5541 | ETA:0.6m\n",
      "  E3 S11500/12297 | Loss:2.5501 | ETA:0.4m\n",
      "  E3 S12000/12297 | Loss:2.5757 | ETA:0.1m\n",
      "\n",
      "âœ… Epoch 3 complete: avg_loss=2.5919 (5.6m)\n",
      "   ğŸ’¾ Saved: /home/T2510596/Downloads/totally fresh/thesis_final/weights/ssl/bimamba_masking_ssl_epoch_3.pth\n",
      "\n",
      "âœ… Training complete!\n",
      "   ğŸ’¾ Final: /home/T2510596/Downloads/totally fresh/thesis_final/weights/ssl/bimamba_masking_ssl_final.pth\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "if start_epoch < SSL_EPOCHS:\n",
    "    print(f\"\\nğŸ”„ Training epochs {start_epoch+1}-{SSL_EPOCHS}\\n\")\n",
    "    \n",
    "    for epoch in range(start_epoch, SSL_EPOCHS):\n",
    "        encoder.train()\n",
    "        total_loss = 0\n",
    "        steps = 0\n",
    "        start_time = time.time()\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"Epoch {epoch+1}/{SSL_EPOCHS}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        for step, (x, x_aug) in enumerate(pretrain_loader):\n",
    "            x = x.to(DEVICE)\n",
    "            x_aug = x_aug.to(DEVICE)\n",
    "            \n",
    "            # Forward pass (both augmented views)\n",
    "            optimizer.zero_grad()\n",
    "            z_i, _ = encoder(x)\n",
    "            z_j, _ = encoder(x_aug)\n",
    "            \n",
    "            # Contrastive loss\n",
    "            loss = nt_xent_loss(z_i, z_j, temperature=TEMPERATURE)\n",
    "            \n",
    "            # Backward\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            steps += 1\n",
    "            \n",
    "            # Log progress\n",
    "            if (step + 1) % 500 == 0:\n",
    "                elapsed = time.time() - start_time\n",
    "                eta = (elapsed / (step + 1)) * (len(pretrain_loader) - step - 1)\n",
    "                msg = f\"  E{epoch+1} S{step+1:>5d}/{len(pretrain_loader)} | Loss:{loss.item():.4f} | ETA:{eta/60:.1f}m\"\n",
    "                print(msg)\n",
    "                with open(log_file, 'a') as f:\n",
    "                    f.write(msg + \"\\n\")\n",
    "        \n",
    "        # Epoch summary\n",
    "        avg_loss = total_loss / steps\n",
    "        elapsed = time.time() - start_time\n",
    "        msg = f\"âœ… Epoch {epoch+1} complete: avg_loss={avg_loss:.4f} ({elapsed/60:.1f}m)\"\n",
    "        print(f\"\\n{msg}\")\n",
    "        with open(log_file, 'a') as f:\n",
    "            f.write(msg + \"\\n\")\n",
    "        \n",
    "        # Save checkpoint\n",
    "        ckpt_path = os.path.join(WEIGHTS_DIR, f\"bimamba_masking_ssl_epoch_{epoch+1}.pth\")\n",
    "        torch.save(encoder.state_dict(), ckpt_path)\n",
    "        print(f\"   ğŸ’¾ Saved: {ckpt_path}\")\n",
    "        \n",
    "        # Update last epoch\n",
    "        with open(last_epoch_file, 'w') as f:\n",
    "            f.write(str(epoch))\n",
    "    \n",
    "    # Save final\n",
    "    torch.save(encoder.state_dict(), final_weight_path)\n",
    "    print(f\"\\nâœ… Training complete!\")\n",
    "    print(f\"   ğŸ’¾ Final: {final_weight_path}\")\n",
    "    \n",
    "    # Cleanup\n",
    "    if os.path.exists(last_epoch_file):\n",
    "        os.remove(last_epoch_file)\n",
    "else:\n",
    "    print(f\"\\nâœ… Training already complete (all {SSL_EPOCHS} epochs done)\")\n",
    "\n",
    "# Cleanup GPU\n",
    "encoder.cpu()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99578fc",
   "metadata": {},
   "source": [
    "## Stage 9: Verification & Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9659b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STAGE 9: Verification & Testing\n",
      "======================================================================\n",
      "\n",
      "ğŸ“‚ Loading final model...\n",
      "âœ… Model loaded\n",
      "\n",
      "ğŸ§ª Testing on sample batch...\n",
      "   Input: torch.Size([64, 32, 5])\n",
      "   Contrastive output: torch.Size([64, 128]) âœ…\n",
      "   Reconstruction output: torch.Size([64, 32, 5]) âœ…\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*70}\\nSTAGE 9: Verification & Testing\\n{'='*70}\")\n",
    "\n",
    "print(f\"\\nğŸ“‚ Loading final model...\")\n",
    "encoder = BiMambaEncoder(d_model=256, n_layers=4).to(DEVICE)\n",
    "encoder.load_state_dict(torch.load(final_weight_path, map_location=DEVICE, weights_only=False))\n",
    "encoder.eval()\n",
    "print(\"âœ… Model loaded\")\n",
    "\n",
    "print(f\"\\nğŸ§ª Testing on sample batch...\")\n",
    "with torch.no_grad():\n",
    "    x_test, x_aug_test = next(iter(pretrain_loader))\n",
    "    x_test = x_test.to(DEVICE)\n",
    "    z, recon = encoder(x_test)\n",
    "    print(f\"   Input: {x_test.shape}\")\n",
    "    print(f\"   Contrastive output: {z.shape} âœ…\")\n",
    "    print(f\"   Reconstruction output: {recon.shape} âœ…\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67676bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Computing unsupervised AUC...\n",
      "   Unsupervised AUC: 0.1008 âœ…\n"
     ]
    }
   ],
   "source": [
    "# Compute unsupervised AUC\n",
    "print(f\"\\nğŸ“Š Computing unsupervised AUC...\")\n",
    "with open(FINETUNE_PKL, 'rb') as f:\n",
    "    finetune_sample = pickle.load(f)[:5000]\n",
    "\n",
    "# Split benign vs attack\n",
    "benign_test = [d for d in finetune_sample if d['label'] == 0][:2500]\n",
    "attack_test = [d for d in finetune_sample if d['label'] == 1][:2500]\n",
    "test_flows = benign_test + attack_test\n",
    "test_labels = [0]*len(benign_test) + [1]*len(attack_test)\n",
    "benign_ref = pretrain_data[:2000]\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Encode reference (benign)\n",
    "    ref_reps = []\n",
    "    for i in range(0, len(benign_ref), 256):\n",
    "        batch = benign_ref[i:i+256]\n",
    "        feats = np.stack([d['features'] if isinstance(d, dict) else d for d in batch])\n",
    "        x = torch.from_numpy(feats).float().to(DEVICE)\n",
    "        z, _ = encoder(x)\n",
    "        ref_reps.append(z.cpu().numpy())\n",
    "    ref_reps = np.concatenate(ref_reps, axis=0)\n",
    "    ref_reps = ref_reps / (np.linalg.norm(ref_reps, axis=1, keepdims=True) + 1e-8)\n",
    "    \n",
    "    # Encode test\n",
    "    test_reps = []\n",
    "    for i in range(0, len(test_flows), 256):\n",
    "        batch = test_flows[i:i+256]\n",
    "        feats = np.stack([d['features'] if isinstance(d, dict) else d for d in batch])\n",
    "        x = torch.from_numpy(feats).float().to(DEVICE)\n",
    "        z, _ = encoder(x)\n",
    "        test_reps.append(z.cpu().numpy())\n",
    "    test_reps = np.concatenate(test_reps, axis=0)\n",
    "    test_reps = test_reps / (np.linalg.norm(test_reps, axis=1, keepdims=True) + 1e-8)\n",
    "    \n",
    "    # Compute anomaly scores (distance to benign reference)\n",
    "    scores = []\n",
    "    for i in range(0, len(test_reps), 200):\n",
    "        chunk = test_reps[i:i+200]\n",
    "        sim = chunk @ ref_reps.T  # Cosine similarity\n",
    "        topk = np.sort(sim, axis=1)[:, -10:]  # Top 10 similarity\n",
    "        scores.extend(topk.mean(axis=1).tolist())  # Average\n",
    "    \n",
    "    auc = roc_auc_score(test_labels, scores)\n",
    "    print(f\"   Unsupervised AUC: {auc:.4f} âœ…\")\n",
    "\n",
    "# Cleanup\n",
    "encoder.cpu()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df20d632",
   "metadata": {},
   "source": [
    "## Summary: Pipeline Complete âœ…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "812e06cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PIPELINE COMPLETION SUMMARY\n",
      "======================================================================\n",
      "\n",
      "âœ… Complete SSL Pretraining Pipeline Done!\n",
      "\n",
      "ğŸ“ Outputs Saved:\n",
      "   Weights:  /home/T2510596/Downloads/totally fresh/thesis_final/weights/ssl/bimamba_masking_ssl_final.pth\n",
      "   Logs:     /home/T2510596/Downloads/totally fresh/thesis_final/results_ssl_pipeline/logs/ssl_pretraining.log\n",
      "\n",
      "ğŸ¯ Ready for:\n",
      "   1. Supervised fine-tuning\n",
      "   2. Student distillation\n",
      "   3. Cross-dataset evaluation\n",
      "\n",
      "â±ï¸ Performance:\n",
      "   Unsupervised AUC: 0.1008\n",
      "   Model size: ~3.65M parameters\n",
      "\n",
      "âœ¨ Checkpoint Features:\n",
      "   âœ… Skips re-processing if outputs exist\n",
      "   âœ… Resumes from last epoch if interrupted\n",
      "   âœ… Full logging included\n",
      "   âœ… Absolute paths (no relative path issues)\n",
      "   âœ… Centralized weight storage (ssl/ folder)\n",
      "\n",
      "======================================================================\n",
      "âœ… FULL PIPELINE COMPLETE!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*70}\")\n",
    "print(\"PIPELINE COMPLETION SUMMARY\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "print(f\"\"\"\n",
    "âœ… Complete SSL Pretraining Pipeline Done!\n",
    "\n",
    "ğŸ“ Outputs Saved:\n",
    "   Weights:  {final_weight_path}\n",
    "   Logs:     {log_file}\n",
    "\n",
    "ğŸ¯ Ready for:\n",
    "   1. Supervised fine-tuning\n",
    "   2. Student distillation\n",
    "   3. Cross-dataset evaluation\n",
    "\n",
    "â±ï¸ Performance:\n",
    "   Unsupervised AUC: {auc:.4f}\n",
    "   Model size: ~3.65M parameters\n",
    "   \n",
    "âœ¨ Checkpoint Features:\n",
    "   âœ… Skips re-processing if outputs exist\n",
    "   âœ… Resumes from last epoch if interrupted\n",
    "   âœ… Full logging included\n",
    "   âœ… Absolute paths (no relative path issues)\n",
    "   âœ… Centralized weight storage (ssl/ folder)\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"âœ… FULL PIPELINE COMPLETE!\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mamba_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
